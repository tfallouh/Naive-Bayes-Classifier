{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T17:25:53.170150Z",
     "start_time": "2024-09-10T17:25:51.974204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Création d'un DataFrame pandas\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['species'] = pd.Categorical.from_codes(y, target_names)\n",
    "\n",
    "# Affichage des premières lignes du DataFrame\n",
    "print(df.head(150))"
   ],
   "id": "4b118ac4a2d0095",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                  5.1               3.5                1.4               0.2   \n",
      "1                  4.9               3.0                1.4               0.2   \n",
      "2                  4.7               3.2                1.3               0.2   \n",
      "3                  4.6               3.1                1.5               0.2   \n",
      "4                  5.0               3.6                1.4               0.2   \n",
      "..                 ...               ...                ...               ...   \n",
      "145                6.7               3.0                5.2               2.3   \n",
      "146                6.3               2.5                5.0               1.9   \n",
      "147                6.5               3.0                5.2               2.0   \n",
      "148                6.2               3.4                5.4               2.3   \n",
      "149                5.9               3.0                5.1               1.8   \n",
      "\n",
      "       species  \n",
      "0       setosa  \n",
      "1       setosa  \n",
      "2       setosa  \n",
      "3       setosa  \n",
      "4       setosa  \n",
      "..         ...  \n",
      "145  virginica  \n",
      "146  virginica  \n",
      "147  virginica  \n",
      "148  virginica  \n",
      "149  virginica  \n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T13:04:13.816678Z",
     "start_time": "2024-09-11T13:03:52.294579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Charger le dataset IRIS\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "classes = np.unique(y)\n",
    "\n",
    "# Séparer le dataset en données d'entraînement et de test en utilisant la stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Afficher les formes des données pour vérifier la division\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Calculer les probabilités a priori pour chaque classe\n",
    "def calculate_prior(y_train, classes):\n",
    "    priors = {}\n",
    "    total_count = len(y_train)\n",
    "    class_counts = np.bincount(y_train)  # Compte le nombre d'instances pour chaque classe\n",
    "    for c in classes:\n",
    "        priors[c] = class_counts[c] / total_count  # Calcule la probabilité a priori pour chaque classe\n",
    "    return priors\n",
    "\n",
    "# Afficher les probabilités a priori\n",
    "priors = calculate_prior(y_train, classes)\n",
    "print(\"Probabilités a priori pour chaque classe :\")\n",
    "for cls, prob in priors.items():\n",
    "    print(f\"Classe {cls}: {prob:.4f}\")\n",
    "\n",
    "# Calculer les moyennes et variances pour chaque attribut par classe\n",
    "def calculate_mean_variance(X_train, y_train, classes):\n",
    "    mean_var = {}\n",
    "    for c in classes:\n",
    "        X_c = X_train[y_train == c]  # Sélectionne les instances de la classe c\n",
    "        mean_var[c] = {\n",
    "            'mean': np.mean(X_c, axis=0),  # Calcule la moyenne des attributs pour la classe c\n",
    "            'var': np.var(X_c, axis=0)  # Calcule la variance des attributs pour la classe c\n",
    "        }\n",
    "    return mean_var\n",
    "\n",
    "# Affiche les moyennes et variances des attributs par classe\n",
    "mean_var = calculate_mean_variance(X_train, y_train, classes)\n",
    "print(\"\\nMoyennes et variances pour chaque attribut par classe :\")\n",
    "for cls, stats in mean_var.items():\n",
    "    print(f\"Classe {cls}:\")\n",
    "    print(f\"  Moyennes: {stats['mean']}\")\n",
    "    print(f\"  Variances: {stats['var']}\")\n",
    "\n",
    "# Densité de probabilité d'une distribution normale\n",
    "def gaussian_density(x, mean, var):\n",
    "    exponent = np.exp(-((x - mean) ** 2) / (2 * var))  # Calcule la partie exponentielle de la densité\n",
    "    return (1 / np.sqrt(2 * np.pi * var)) * exponent  # Calcule la densité de probabilité\n",
    "\n",
    "# Calcul de la probabilité postérieure pour une instance donnée\n",
    "def calculate_posterior(X, priors, mean_var, classes):\n",
    "    posteriors = []\n",
    "    for c in classes:\n",
    "        prior = np.log(priors[c])  # Prend le logarithme de la probabilité a priori\n",
    "        conditional = np.sum(np.log(gaussian_density(X, mean_var[c]['mean'], mean_var[c]['var'])))  # Calcule la somme des logs des vraisemblances\n",
    "        posterior = prior + conditional  # Calcule la log-probabilité postérieure\n",
    "        posteriors.append(posterior)\n",
    "    return classes[np.argmax(posteriors)], posteriors  # Retourne la classe avec la plus grande probabilité postérieure et les probabilités\n",
    "\n",
    "# Entraînement du modèle\n",
    "priors = calculate_prior(y_train, classes)\n",
    "mean_var = calculate_mean_variance(X_train, y_train, classes)\n",
    "\n",
    "# Prédiction de la classe pour une nouvelle instance\n",
    "def predict(X, priors, mean_var, classes):\n",
    "    predictions = []\n",
    "    for instance in X:\n",
    "        predicted_class, posteriors = calculate_posterior(instance, priors, mean_var, classes)\n",
    "        predictions.append(predicted_class)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Prédictions sur le dataset de test\n",
    "y_pred = predict(X_test, priors, mean_var, classes)\n",
    "\n",
    "# Évaluation de la précision\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f'\\nAccuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Saisie d'une nouvelle instance\n",
    "print(\"\\nEntrez les valeurs pour une nouvelle instance :\")\n",
    "new_instance = np.array([\n",
    "    float(input(\"Longueur du sépale (4.3 - 7.9 cm) : \")),\n",
    "    float(input(\"Largeur du sépale (2.0 - 4.4 cm) : \")),\n",
    "    float(input(\"Longueur du pétale (1.0 - 6.9 cm) : \")),\n",
    "    float(input(\"Largeur du pétale (0.1 - 2.5 cm) : \"))\n",
    "]).reshape(1, -1)\n",
    "\n",
    "# Affichage des valeurs de la nouvelle instance\n",
    "print(\"\\nValeurs de la nouvelle instance :\")\n",
    "print(f\"Longueur du sépale: {new_instance[0, 0]} cm\")\n",
    "print(f\"Largeur du sépale: {new_instance[0, 1]} cm\")\n",
    "print(f\"Longueur du pétale: {new_instance[0, 2]} cm\")\n",
    "print(f\"Largeur du pétale: {new_instance[0, 3]} cm\")\n",
    "# Prédire la classe pour la nouvelle instance\n",
    "predicted_class, posteriors = calculate_posterior(new_instance, priors, mean_var, classes)\n",
    "print(f'\\nClasse prédite pour la nouvelle instance: {predicted_class}')\n",
    "\n",
    "# Affichage des log-probabilités postérieures pour la nouvelle instance\n",
    "print(\"\\nLog-probabilités postérieures pour la nouvelle instance :\")\n",
    "for cls, posterior in zip(classes, posteriors):\n",
    "    print(f\"Classe {cls}: {posterior:.4f}\")\n",
    "\n",
    "# Affichage de la densité de probabilité pour la nouvelle instance\n",
    "print(\"\\nDensités de probabilité pour la nouvelle instance :\")\n",
    "for cls, stats in mean_var.items():\n",
    "    densities = gaussian_density(new_instance, stats['mean'], stats['var'])\n",
    "    print(f\"Classe {cls}: {densities}\")\n"
   ],
   "id": "f14025691cbc664a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (105, 4)\n",
      "X_test shape: (45, 4)\n",
      "y_train shape: (105,)\n",
      "y_test shape: (45,)\n",
      "Probabilités a priori pour chaque classe :\n",
      "Classe 0: 0.3333\n",
      "Classe 1: 0.3333\n",
      "Classe 2: 0.3333\n",
      "\n",
      "Moyennes et variances pour chaque attribut par classe :\n",
      "Classe 0:\n",
      "  Moyennes: [4.98857143 3.42571429 1.48571429 0.24      ]\n",
      "  Variances: [0.10329796 0.1739102  0.02293878 0.00925714]\n",
      "Classe 1:\n",
      "  Moyennes: [5.94857143 2.73142857 4.23714286 1.30857143]\n",
      "  Variances: [0.24078367 0.08558367 0.21147755 0.03564082]\n",
      "Classe 2:\n",
      "  Moyennes: [6.68285714 3.00857143 5.63142857 2.06857143]\n",
      "  Variances: [0.42484898 0.1173551  0.32272653 0.06386939]\n",
      "\n",
      "Accuracy: 91.11%\n",
      "\n",
      "Entrez les valeurs pour une nouvelle instance :\n",
      "\n",
      "Valeurs de la nouvelle instance :\n",
      "Longueur du sépale: 5.0 cm\n",
      "Largeur du sépale: 3.0 cm\n",
      "Longueur du pétale: 2.0 cm\n",
      "Largeur du pétale: 2.0 cm\n",
      "\n",
      "Classe prédite pour la nouvelle instance: 1\n",
      "\n",
      "Log-probabilités postérieures pour la nouvelle instance :\n",
      "Classe 0: -172.1315\n",
      "Classe 1: -21.2190\n",
      "Classe 2: -25.1353\n",
      "\n",
      "Densités de probabilité pour la nouvelle instance :\n",
      "Classe 0: [[1.24047961e+00 5.68142605e-01 8.25777734e-03 9.04589616e-73]]\n",
      "Classe 1: [[1.25497795e-01 8.94748858e-01 6.29928719e-06 2.58344340e-03]]\n",
      "Classe 2: [[2.18427455e-02 1.16418804e+00 9.40605221e-10 1.52151903e+00]]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T15:13:52.122381Z",
     "start_time": "2024-08-18T15:13:52.106780Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3ab78af4bb20d201",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cc480a2cd80635ca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
